{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa75819c-7a08-4a97-a3ea-30da40b659c9",
   "metadata": {},
   "source": [
    "# Laboratorio: Implementación de un modelo de Machine Learning\n",
    "\n",
    "Esta experiencia de laboratorio se trata de implementar un modelo de ML para clasificación binaria usando datos tabulares. Para eso usaremos el modelo ya ajustado en el notebook [00_supervivencia_titanic.ipynb]. Para implementar el modelo como un servicio usaremos la popular biblioteca [`fastAPI`](https://fastapi.tiangolo.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca535d5-5839-4f58-a10b-5bad01e47209",
   "metadata": {},
   "source": [
    "## Clasificación binaria de datos tabulares usando Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afbcb7a-ee83-4889-869d-561f2078a87a",
   "metadata": {},
   "source": [
    "### Creando la función predict_supervivencia_titanic\n",
    "\n",
    "Vamos a crear el método `predict_supervivencia_titanic` que toma como entradas un **array con los valores de las características del viaje** y un **umbral de confianza**. La función determinará si el viaje es de clase propina alta o propina baja, devolviendo un 1 o un 0 dependiendo del caso.\n",
    "\n",
    "La salida del modelo es un vector de probabilidades de pertenencia del viaje a alguna de las dos clases posibles. El último argumento de entrada a nuestra función (el nivel de confianza) será el umbral que dichas probabilidades deben superar para determinar que el viaje en cuestión si representa uno de propina alta. Por defecto `predict_taxi_trip` usa el valor 0.5 para esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c095fa46-9bb7-4eee-8996-be3293742792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 01_server_titanic.ipynb ===\n",
    "# Servidor FastAPI para el modelo de supervivencia del Titanic\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional, Literal\n",
    "\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a331c88-66ee-40e3-a23b-bbd0ac0eacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Cargar artefacto del modelo\n",
    "# -----------------------------\n",
    "ARTIFACT_PATH = \"model/logistic_titanic_pipeline.pkl\"\n",
    "if not os.path.exists(ARTIFACT_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"No se encontró {ARTIFACT_PATH}. Entrena y guarda el modelo en el notebook 00 primero.\"\n",
    "    )\n",
    "\n",
    "artifact = joblib.load(ARTIFACT_PATH)\n",
    "pipe = artifact[\"model\"]\n",
    "DEFAULT_THRESHOLD = float(artifact.get(\"threshold\", 0.5))\n",
    "EXPECTED_FEATURES = artifact.get(\n",
    "    \"features\",\n",
    "    ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']  # fallback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22f8a4c7-8630-4068-9663-7282c62afd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2) Definición de la API\n",
    "# -----------------------------\n",
    "app = FastAPI(\n",
    "    title=\"API - Supervivencia Titanic\",\n",
    "    description=\"Clasificador binario de supervivencia usando Pipeline de scikit-learn.\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Schema de entrada (campos crudos; el Pipeline se encarga del preprocesamiento)\n",
    "class Passenger(BaseModel):\n",
    "    pclass: Literal[1, 2, 3] = Field(..., description=\"Clase del boleto (1, 2, 3)\")\n",
    "    sex: Literal[\"male\", \"female\"] = Field(..., description=\"Sexo del pasajero\")\n",
    "    age: Optional[float] = Field(None, ge=0, le=100, description=\"Edad en años (puede ser nula)\")\n",
    "    sibsp: int = Field(..., ge=0, description=\"Hnos/cónyuges a bordo\")\n",
    "    parch: int = Field(..., ge=0, description=\"Padres/hijos a bordo\")\n",
    "    fare: Optional[float] = Field(None, ge=0, description=\"Tarifa pagada (puede ser nula)\")\n",
    "    embarked: Optional[Literal[\"C\", \"Q\", \"S\"]] = Field(None, description=\"Puerto de embarque\")\n",
    "\n",
    "    # normalizamos por si vienen en minúsculas / mayúsculas mezcladas\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        row = {\n",
    "            \"pclass\": int(self.pclass),\n",
    "            \"sex\": str(self.sex).lower(),\n",
    "            \"age\": self.age,\n",
    "            \"sibsp\": int(self.sibsp),\n",
    "            \"parch\": int(self.parch),\n",
    "            \"fare\": self.fare,\n",
    "            \"embarked\": None if self.embarked is None else str(self.embarked).upper(),\n",
    "        }\n",
    "        # asegurar orden de columnas esperado por el pipeline\n",
    "        return pd.DataFrame([row], columns=EXPECTED_FEATURES)\n",
    "\n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return {\n",
    "        \"message\": \"¡API Titanic OK! Visita /docs para probar.\",\n",
    "        \"default_threshold\": DEFAULT_THRESHOLD,\n",
    "        \"expected_features\": EXPECTED_FEATURES,\n",
    "    }\n",
    "\n",
    "\n",
    "@app.get(\"/healthz\")\n",
    "def healthz():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(passenger: Passenger, confidence: Optional[float] = None):\n",
    "    \"\"\"\n",
    "    Predice supervivencia para un pasajero.\n",
    "    - Usa 'confidence' como umbral si se especifica; de lo contrario usa el umbral guardado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = passenger.to_dataframe()\n",
    "        # Probabilidad de clase positiva (sobrevive = 1)\n",
    "        proba = float(pipe.predict_proba(X)[0, 1])\n",
    "        thr = float(confidence) if confidence is not None else DEFAULT_THRESHOLD\n",
    "        pred = int(proba >= thr)\n",
    "        label = \"Sobrevive\" if pred == 1 else \"No sobrevive\"\n",
    "        return {\n",
    "            \"threshold_used\": thr,\n",
    "            \"prob_survive\": proba,\n",
    "            \"pred_class\": int(pred),\n",
    "            \"pred_label\": label,\n",
    "            \"features_order\": EXPECTED_FEATURES,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=f\"Error en predicción: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25fee08-4a3a-4977-978e-b1b3330c3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [14236]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49394 - \"POST /predict?confidence=0.55 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:49395 - \"POST /predict?confidence=0.55 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:49396 - \"POST /predict?confidence=0.55 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:49397 - \"POST /predict?confidence=0.55 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:49398 - \"GET /predict?confidence=0.55 HTTP/1.1\" 405 Method Not Allowed\n",
      "INFO:     127.0.0.1:49398 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:49403 - \"GET /predict HTTP/1.1\" 405 Method Not Allowed\n",
      "INFO:     127.0.0.1:49402 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:49402 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:49405 - \"POST /predict HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3) Ejecutar servidor (en notebook)\n",
    "# -----------------------------\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8779c-0f53-4ff1-b776-9ba83f6cea79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (producto-datos-lab)",
   "language": "python",
   "name": "producto-datos-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
