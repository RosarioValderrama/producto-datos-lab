{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1605f66-404b-48df-be37-84af410399f0",
   "metadata": {},
   "source": [
    "# Clasificador de supervivencia de pasajeros del Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77352697-c389-4e4b-abc6-c161f3d4cb4a",
   "metadata": {},
   "source": [
    "Este notebook presenta la construcción de un modelo de **clasificación supervisada** utilizando el clásico **dataset del Titanic**, el cual contiene información sobre los pasajeros del barco hundido en 1912.  \n",
    "El **objetivo principal** es predecir la **probabilidad de supervivencia** de un pasajero a partir de atributos como su edad, sexo, clase en la que viajaba, número de familiares a bordo y puerto de embarque.\n",
    "\n",
    "A diferencia de un flujo manual de preprocesamiento, en este trabajo se empleará un **Pipeline de scikit-learn**, el cual permite integrar en una sola estructura tanto el tratamiento de los datos (imputación de valores faltantes, codificación de variables categóricas y normalización de variables numéricas) como el modelo de clasificación.  \n",
    "\n",
    "Se utilizará algoritmo de **clasificación binaria** - **Regresión Logística.** El rendimiento se evaluará mediante métricas como la **precisión** y el **f1-score**.\n",
    "\n",
    "Finalmente, se ilustrará cómo aplicar el modelo entrenado a **casos individuales**, prediciendo la probabilidad de supervivencia de pasajeros específicos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63973b20-dddc-4e43-9c22-06ab7295cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, f1_score, precision_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f1c06-b319-4d48-8cfa-1812a0db3405",
   "metadata": {},
   "source": [
    "## Obtención del Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d6d54-156a-4381-9065-1e666cbe13f1",
   "metadata": {},
   "source": [
    "La descarga del dataset `titanic` se realiza desde OpenML por medio de fetch_openml. Esta función de scikit-learn permite la descarga de datasets desde la plataforma OpenML.\n",
    "\n",
    "Para este caso, se imprimen las variables predictorias como X_titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62402068-dbfe-483b-9db2-800b8ef4576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pclass', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare',\n",
      "       'cabin', 'embarked', 'boat', 'body', 'home.dest'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_titanic, y_titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "print(X_titanic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8dcdd13-dd47-4ffb-9fae-4f28cb6643bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass                                             name     sex      age  \\\n",
       "0       1                    Allen, Miss. Elisabeth Walton  female  29.0000   \n",
       "1       1                   Allison, Master. Hudson Trevor    male   0.9167   \n",
       "2       1                     Allison, Miss. Helen Loraine  female   2.0000   \n",
       "3       1             Allison, Mr. Hudson Joshua Creighton    male  30.0000   \n",
       "4       1  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000   \n",
       "\n",
       "   sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b499781-3be1-47c4-a35b-fe5cd5e5b248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Métricas (umbral 0.5) ===\n",
      "F1: 0.7357512953367875\n",
      "Accuracy: 0.8053435114503816\n",
      "Precision: 0.7634408602150538\n",
      "Recall: 0.71\n",
      "ROC-AUC: 0.8673148148148149\n",
      "Matriz de confusión:\n",
      " [[140  22]\n",
      " [ 29  71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       162\n",
      "           1       0.76      0.71      0.74       100\n",
      "\n",
      "    accuracy                           0.81       262\n",
      "   macro avg       0.80      0.79      0.79       262\n",
      "weighted avg       0.80      0.81      0.80       262\n",
      "\n",
      "\n",
      "=== Búsqueda de umbral por F1 (en test) ===\n",
      "Mejor umbral: 0.550  |  F1: 0.7634\n",
      "\n",
      "=== Métricas con umbral óptimo (F1) ===\n",
      "F1: 0.7634408602150538\n",
      "Accuracy: 0.8320610687022901\n",
      "Precision: 0.8255813953488372\n",
      "Recall: 0.71\n",
      "Matriz de confusión:\n",
      " [[147  15]\n",
      " [ 29  71]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/logistic_titanic_meta.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Imports\n",
    "# =========================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, accuracy_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2) Configuración de columnas\n",
    "# =========================\n",
    "# Ajusta estos nombres a los de tu DataFrame X_titanic\n",
    "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
    "\n",
    "numeric_features = ['age', 'sibsp', 'parch', 'fare']\n",
    "categorical_features = ['pclass', 'sex', 'embarked']\n",
    "\n",
    "# =========================\n",
    "# 3) Preprocesadores y Pipeline\n",
    "# =========================\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),   # rellena nulos con mediana\n",
    "    ('scaler', StandardScaler())                     # escala numéricas\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # rellena nulos con moda\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))     # one-hot encoding\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# 4) Train / Test split\n",
    "# =========================\n",
    "# y_titanic debería ser binaria (0/1). Si no lo es, intenta castear:\n",
    "try:\n",
    "    y_titanic = y_titanic.astype(int)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_titanic[features], y_titanic, test_size=0.2, random_state=42, stratify=y_titanic\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 5) Entrenamiento\n",
    "# =========================\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# =========================\n",
    "# 6) Métricas con umbral por defecto (0.5)\n",
    "# =========================\n",
    "y_pred_05 = clf.predict(X_test)                                   # usa 0.5 internamente\n",
    "y_proba   = clf.predict_proba(X_test)[:, 1]                       # prob de clase positiva (sobrevive=1)\n",
    "\n",
    "print(\"=== Métricas (umbral 0.5) ===\")\n",
    "print(\"F1:\", f1_score(y_test, y_pred_05))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_05))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_05))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_05))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred_05))\n",
    "print(classification_report(y_test, y_pred_05))\n",
    "\n",
    "# =========================\n",
    "# 7) (Opcional) Buscar umbral que maximiza F1 en X_test\n",
    "#    *Para un trabajo más “purista”, separa un set de validación.\n",
    "# =========================\n",
    "thresholds = np.linspace(0.1, 0.9, 33)\n",
    "f1s = []\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_proba >= t).astype(int)\n",
    "    f1s.append((t, f1_score(y_test, y_pred_t)))\n",
    "\n",
    "best_threshold, best_f1 = max(f1s, key=lambda x: x[1])\n",
    "\n",
    "print(\"\\n=== Búsqueda de umbral por F1 (en test) ===\")\n",
    "print(f\"Mejor umbral: {best_threshold:.3f}  |  F1: {best_f1:.4f}\")\n",
    "\n",
    "# Métricas con el mejor umbral encontrado\n",
    "y_pred_best = (y_proba >= best_threshold).astype(int)\n",
    "print(\"\\n=== Métricas con umbral óptimo (F1) ===\")\n",
    "print(\"F1:\", f1_score(y_test, y_pred_best))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_best))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_best))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "\n",
    "# =========================\n",
    "# 8) Guardar artefacto (modelo + umbral)\n",
    "# =========================\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# 1) Guarda SOLO el estimator/pipeline\n",
    "joblib.dump(clf, \"model/logistic_titanic_pipeline.pkl\")\n",
    "\n",
    "# 2) (Opcional) guarda metadatos por separado\n",
    "meta = {\n",
    "    \"threshold\": float(best_threshold),\n",
    "    \"features\": features\n",
    "}\n",
    "joblib.dump(meta, \"model/logistic_titanic_meta.pkl\")\n",
    "# o en JSON:\n",
    "# with open(\"model/logistic_titanic_meta.json\", \"w\") as f:\n",
    "#     json.dump(meta, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "607f5735-965e-4571-bac3-66deaf93e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo → Probabilidad de sobrevivir: 0.963  → Sobrevive (umbral=0.55)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Cargar el pipeline (el estimator)\n",
    "pipe = joblib.load(\"model/logistic_titanic_pipeline.pkl\")\n",
    "\n",
    "# 2) Cargar metadatos (umbral, etc.)\n",
    "meta = joblib.load(\"model/logistic_titanic_meta.pkl\")\n",
    "thr = float(meta.get(\"threshold\", 0.5))  # por si acaso\n",
    "\n",
    "# 3) Pasajero de ejemplo (sin preprocesar: el pipeline se encarga)\n",
    "ejemplo = pd.DataFrame([{\n",
    "    \"pclass\": 1,\n",
    "    \"sex\": \"female\",\n",
    "    \"age\": 20,\n",
    "    \"sibsp\": 0,\n",
    "    \"parch\": 1,\n",
    "    \"fare\": 80.0,\n",
    "    \"embarked\": \"C\"\n",
    "}])\n",
    "\n",
    "# 4) Predecir probabilidad y aplicar umbral\n",
    "p = pipe.predict_proba(ejemplo)[0, 1]\n",
    "y_hat = int(p >= thr)\n",
    "\n",
    "print(f\"Ejemplo → Probabilidad de sobrevivir: {p:.3f}  → \"\n",
    "      f\"{'Sobrevive' if y_hat==1 else 'No sobrevive'} (umbral={thr:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (producto-datos-lab)",
   "language": "python",
   "name": "producto-datos-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
