{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ffbd40-2249-4d5a-b688-6ecc74379da1",
   "metadata": {},
   "source": [
    "# Clasificador de supervivencia de pasajeros del Titanic\n",
    "\n",
    "Este notebook construye un **pipeline de scikit-learn** (imputación, codificación One-Hot, escalado y Reg.Logística) para predecir la **probabilidad de supervivencia** en el dataset clásico del Titanic.  \n",
    "Se evalúa con métricas de clasificación (F1, accuracy, precision, recall, ROC-AUC) y se selecciona un **umbral óptimo por F1**. Finalmente se exporta un **artefacto (.pkl)** con el modelo y metadatos para usarlo en la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63973b20-dddc-4e43-9c22-06ab7295cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, f1_score, precision_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f1c06-b319-4d48-8cfa-1812a0db3405",
   "metadata": {},
   "source": [
    "## Obtención del dataset (OpenML)\r\n",
    "\r\n",
    "Usamos `fetch_openml` de **scikit-learn** para descargar el conjunto **titanic** desde OpenML:\r\n",
    "\r\n",
    "- `as_frame=True` → entrega los datos como `pandas.DataFrame`/`Series`.\r\n",
    "- `return_X_y=True` → retorna directamente `X_titanic` (características) y `y_titanic` (objetivo).\r\n",
    "- El objetivo es **`survived`** (0 = no sobrevive, 1 = sobrevive).\r\n",
    "\r\n",
    "El `DataFrame` incluye muchas columnas crudas (p. ej. `name`, `ticket`, `cabin`, `home.dest`, etc.).  \r\n",
    "En este trabajo **solo utilizaremos** las siguientes variables predictoras:\r\n",
    "\r\n",
    "- `pclass`, `sex`, `age`, `sibsp`, `parch`, `fare`, `embarked`.\r\n",
    "\r\n",
    "El resto se considera **ruido** o **potencial fuga de información** (leakage) y se descarta.  \r\n",
    "Abajo imprimimos las columnas y un `head()` para una inspección rápida antes del preprocesamiento.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62402068-dbfe-483b-9db2-800b8ef4576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pclass', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare',\n",
      "       'cabin', 'embarked', 'boat', 'body', 'home.dest'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_titanic, y_titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "print(X_titanic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcdd13-dd47-4ffb-9fae-4f28cb6643bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass                                             name     sex      age  \\\n",
       "0       1                    Allen, Miss. Elisabeth Walton  female  29.0000   \n",
       "1       1                   Allison, Master. Hudson Trevor    male   0.9167   \n",
       "2       1                     Allison, Miss. Helen Loraine  female   2.0000   \n",
       "3       1             Allison, Mr. Hudson Joshua Creighton    male  30.0000   \n",
       "4       1  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000   \n",
       "\n",
       "   sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975c222-189b-47a3-bc2a-ad278ca308f7",
   "metadata": {},
   "source": [
    "### 1) Imports\r\n",
    "Cargamos librerías de ciencia de datos (**numpy, pandas, joblib**) y de **scikit-learn** para armar el pipeline, entrenar el modelo y calcular métricas (F1, accuracy, precision, recall, ROC-AUC).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 2) Configuración de columnas\r\n",
    "Definimos las variables que usará el modelo:\r\n",
    "- **features**: `['pclass','sex','age','sibsp','parch','fare','embarked']`\r\n",
    "- Separamos numéricas y categóricas para el preprocesamiento.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 3) Preprocesamiento + Pipeline\r\n",
    "- Numéricas: imputación (mediana) + estandarización.\r\n",
    "- Categóricas: imputación (moda) + One-Hot Encoding.\r\n",
    "- Clasificador: **LogisticRegression** dentro de un **Pipeline** completo.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 4) Train/Test split\r\n",
    "Partimos los datos 80/20 con `train_test_split` (semilla 42) y estratificación en el objetivo para mantener proporciones.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 5) Entrenamiento\r\n",
    "Entrenamos el pipeline con `clf.fit(X_train, y_train)`.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 6) Métricas (umbral 0.5)\r\n",
    "Calculamos predicciones y probabilidades con el umbral por defecto (0.5) y reportamos F1, accuracy, precision, recall, ROC-AUC y matriz de confusión.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 7) Búsqueda de umbral (max F1)\r\n",
    "Barrido simple de umbrales entre 0.1 y 0.9; escogemos el que **maximiza F1** en el set de test y mostramos las métricas resultantes.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 8) Guardar artefacto\r\n",
    "Guardamos **un solo archivo** `model/logistic_titanic_pipeline.pkl` con:\r\n",
    "- `model`: el Pipeline entrenado  \r\n",
    "- `threshold`: umbral óptimo  \r\n",
    "- `features`: columnas esperadas  \r\n",
    "Incluye un sanity check de carga para verificar las llaves.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b499781-3be1-47c4-a35b-fe5cd5e5b248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Métricas (umbral 0.5) ===\n",
      "F1: 0.7357512953367875\n",
      "Accuracy: 0.8053435114503816\n",
      "Precision: 0.7634408602150538\n",
      "Recall: 0.71\n",
      "ROC-AUC: 0.8673148148148149\n",
      "Matriz de confusión:\n",
      " [[140  22]\n",
      " [ 29  71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       162\n",
      "           1       0.76      0.71      0.74       100\n",
      "\n",
      "    accuracy                           0.81       262\n",
      "   macro avg       0.80      0.79      0.79       262\n",
      "weighted avg       0.80      0.81      0.80       262\n",
      "\n",
      "\n",
      "=== Búsqueda de umbral por F1 (en test) ===\n",
      "Mejor umbral: 0.550  |  F1: 0.7634\n",
      "\n",
      "=== Métricas con umbral óptimo (F1) ===\n",
      "F1: 0.7634408602150538\n",
      "Accuracy: 0.8320610687022901\n",
      "Precision: 0.8255813953488372\n",
      "Recall: 0.71\n",
      "Matriz de confusión:\n",
      " [[147  15]\n",
      " [ 29  71]]\n",
      "Artefacto guardado en: model/logistic_titanic_pipeline.pkl\n",
      "Llaves: ['model', 'threshold', 'features']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Imports\n",
    "# =========================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, accuracy_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2) Configuración de columnas\n",
    "# =========================\n",
    "# Ajusta estos nombres a los de tu DataFrame X_titanic\n",
    "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
    "\n",
    "numeric_features = ['age', 'sibsp', 'parch', 'fare']\n",
    "categorical_features = ['pclass', 'sex', 'embarked']\n",
    "\n",
    "# =========================\n",
    "# 3) Preprocesadores y Pipeline\n",
    "# =========================\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),   # rellena nulos con mediana\n",
    "    ('scaler', StandardScaler())                     # escala numéricas\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # rellena nulos con moda\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))     # one-hot encoding\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# 4) Train / Test split\n",
    "# =========================\n",
    "# y_titanic debería ser binaria (0/1). Si no lo es, intenta castear:\n",
    "try:\n",
    "    y_titanic = y_titanic.astype(int)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_titanic[features], y_titanic, test_size=0.2, random_state=42, stratify=y_titanic\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 5) Entrenamiento\n",
    "# =========================\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# =========================\n",
    "# 6) Métricas con umbral por defecto (0.5)\n",
    "# =========================\n",
    "y_pred_05 = clf.predict(X_test)                                   # usa 0.5 internamente\n",
    "y_proba   = clf.predict_proba(X_test)[:, 1]                       # prob de clase positiva (sobrevive=1)\n",
    "\n",
    "print(\"=== Métricas (umbral 0.5) ===\")\n",
    "print(\"F1:\", f1_score(y_test, y_pred_05))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_05))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_05))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_05))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred_05))\n",
    "print(classification_report(y_test, y_pred_05))\n",
    "\n",
    "# =========================\n",
    "# 7) (Opcional) Buscar umbral que maximiza F1 en X_test\n",
    "#    *Para un trabajo más “purista”, separa un set de validación.\n",
    "# =========================\n",
    "thresholds = np.linspace(0.1, 0.9, 33)\n",
    "f1s = []\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_proba >= t).astype(int)\n",
    "    f1s.append((t, f1_score(y_test, y_pred_t)))\n",
    "\n",
    "best_threshold, best_f1 = max(f1s, key=lambda x: x[1])\n",
    "\n",
    "print(\"\\n=== Búsqueda de umbral por F1 (en test) ===\")\n",
    "print(f\"Mejor umbral: {best_threshold:.3f}  |  F1: {best_f1:.4f}\")\n",
    "\n",
    "# Métricas con el mejor umbral encontrado\n",
    "y_pred_best = (y_proba >= best_threshold).astype(int)\n",
    "print(\"\\n=== Métricas con umbral óptimo (F1) ===\")\n",
    "print(\"F1:\", f1_score(y_test, y_pred_best))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_best))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_best))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "\n",
    "# =========================\n",
    "# 8) Guardar artefacto (modelo + umbral + features) en UN SOLO archivo\n",
    "# =========================\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "artifact = {\n",
    "    \"model\": clf,                   # el Pipeline entrenado\n",
    "    \"threshold\": float(best_threshold),\n",
    "    \"features\": features           # ['pclass','sex','age','sibsp','parch','fare','embarked']\n",
    "}\n",
    "\n",
    "joblib.dump(artifact, \"model/logistic_titanic_pipeline.pkl\")\n",
    "print(\"Artefacto guardado en: model/logistic_titanic_pipeline.pkl\")\n",
    "\n",
    "# (Sanity check rápido)\n",
    "_loaded = joblib.load(\"model/logistic_titanic_pipeline.pkl\")\n",
    "print(\"Llaves:\", list(_loaded.keys()))\n",
    "# Deberías ver: ['model', 'threshold', 'features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf1c27-1131-4d88-98d4-4d02069a900b",
   "metadata": {},
   "source": [
    "### Cargar artefacto + predicción de ejemplo\n",
    "\n",
    "**Objetivo:** usar el artefacto persistido para hacer una predicción puntual.\n",
    "\n",
    "1. **Carga del artefacto**  \n",
    "   - Se intenta cargar `model/logistic_titanic_pipeline.pkl` como **diccionario unificado** con:\n",
    "     - `model` → Pipeline entrenado (preprocesa + clasifica)\n",
    "     - `threshold` → umbral óptimo (F1)\n",
    "     - `features` → columnas esperadas (ordenadas)\n",
    "   - **Fallback legado:** si el `.pkl` no trae diccionario, se carga el modelo y, si existe, `model/logistic_titanic_meta.pkl` para obtener `threshold` y `features`.\n",
    "\n",
    "2. **Payload de ejemplo**  \n",
    "   - Se crea un `DataFrame` con los campos crudos (`pclass, sex, age, sibsp, parch, fare, embarked`).\n",
    "   - El **Pipeline** se encarga de imputar, escalar y hacer One-Hot Encoding.\n",
    "\n",
    "3. **Predicción**  \n",
    "   - Se calcula la **probabilidad** de clase positiva con `predict_proba` (sobrevive = 1).\n",
    "   - Se aplica el **umbral** (`threshold`) para obtener la etiqueta final (`0/1`).\n",
    "   - Se imprime: probabilidad, decisión (`Sobrevive / No sobrevive`) y el umbral usado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f5735-965e-4571-bac3-66deaf93e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo → Probabilidad de sobrevivir: 0.963  → Sobrevive (umbral=0.55)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "ARTIFACT_PATH = \"model/logistic_titanic_pipeline.pkl\"\n",
    "META_PATH     = \"model/logistic_titanic_meta.pkl\"  # fallback legacy\n",
    "\n",
    "# 1) Cargar artefacto unificado (modelo + threshold + features)\n",
    "art = joblib.load(ARTIFACT_PATH)\n",
    "\n",
    "if isinstance(art, dict) and \"model\" in art:\n",
    "    pipe      = art[\"model\"]\n",
    "    thr       = float(art.get(\"threshold\", 0.5))\n",
    "    FEATURES  = art.get(\"features\", ['pclass','sex','age','sibsp','parch','fare','embarked'])\n",
    "else:\n",
    "    # Fallback (por si todavía tienes archivos viejos separados)\n",
    "    pipe = art\n",
    "    try:\n",
    "        meta     = joblib.load(META_PATH)\n",
    "        thr      = float(meta.get(\"threshold\", 0.5))\n",
    "        FEATURES = meta.get(\"features\", ['pclass','sex','age','sibsp','parch','fare','embarked'])\n",
    "    except Exception:\n",
    "        thr      = 0.5\n",
    "        FEATURES = ['pclass','sex','age','sibsp','parch','fare','embarked']\n",
    "\n",
    "# 2) Pasajero de ejemplo (el Pipeline hace el preprocesamiento)\n",
    "ejemplo = pd.DataFrame([{\n",
    "    \"pclass\": 1,\n",
    "    \"sex\": \"female\",\n",
    "    \"age\": 20,\n",
    "    \"sibsp\": 0,\n",
    "    \"parch\": 1,\n",
    "    \"fare\": 80.0,\n",
    "    \"embarked\": \"C\"\n",
    "}])\n",
    "\n",
    "# 3) Predecir probabilidad y aplicar umbral\n",
    "p = float(pipe.predict_proba(ejemplo[FEATURES])[:, 1][0])\n",
    "y_hat = int(p >= thr)\n",
    "\n",
    "print(f\"Ejemplo → Probabilidad de sobrevivir: {p:.3f}  → \"\n",
    "      f\"{'Sobrevive' if y_hat==1 else 'No sobrevive'} (umbral={thr:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (producto-datos-lab)",
   "language": "python",
   "name": "producto-datos-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
